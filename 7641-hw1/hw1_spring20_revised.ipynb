{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FFy6leD3ZmzS"
   },
   "source": [
    "# Spring 2020 CX4641/CS7641 Homework 1\n",
    "\n",
    "## Instructor: Dr. Mahdi Roozbahani\n",
    "\n",
    "## Deadline: Jan 30, Thursday, 11:59 pm\n",
    "\n",
    "* Assignments must be turned in before the due date and time indicated to be considered â€on-timeâ€. No late assignments will be accepted. You have weeks to finish the homework and make sure to start early.\n",
    "\n",
    "* Discussion is encouraged, but each student must write his own answers and explicitly mention any collaborators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C2Dz3TFIZmzT"
   },
   "source": [
    "## Instructions for the assignment\n",
    "\n",
    "In this assignment, we only have writing questions: you are asked to answer them in the markdown cells.\n",
    "\n",
    "- Graduate students are required to complete all the questions including **bonus parts** (except for the 5th question which is **bonus for all**). Undergraduate students are welcome to try bouns questions and we will add them on your final grade.\n",
    "\n",
    "- To switch between cell for code and for markdown, see the menu -> Cell -> Cell Type\n",
    "    \n",
    "- You could directly type the Latex equations in the markdown cell.\n",
    "\n",
    "- Typing with Latex\\markdown is required for all the written questions. Handwritten answers would not be accepted. \n",
    "    \n",
    "- If a question requires a picture, you could use this syntax $\"<img src=\"\" style=\"width: 300px;\"/>\"$ to include them within your ipython notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vurwpE07ZmzU"
   },
   "source": [
    "## 1 Linear Algebra (25pts + 8pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6pSyvDOZmzU"
   },
   "source": [
    "### 1.1 Determinant and Inverse of Matrix [11pts]\n",
    "Given a matrix M:\n",
    "\n",
    "$$M = \\begin{bmatrix} \n",
    "  4 & 2 & 0 \\\\ \n",
    "  5 & 3 & 6 \\\\\n",
    "  3 & 2 & k\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- Calculate the determinant of M. [4pts]\n",
    "(Calculation process required. Your answer should be expressed as a function of $k$.)\n",
    "\n",
    "- For which values of k does $M^{-1}$ not exist? Why? [2pts]\n",
    "\n",
    "- Calculate $M^{-1}$ for $k=7$. [5pts]\n",
    "(Calculation process required)\n",
    "\n",
    "  (**Hint:** please double check your answer and make sure $M M^{-1} = I$)\n",
    "  \n",
    "### 1.2 Characteristic Equation [8pts] (BONUS)\n",
    "Consider the eigenvalue problem: \n",
    "  $$Ax =\\lambda x, x \\neq 0$$\n",
    "where $x$ is a non-zero eigenvector and $\\lambda$ is eigenvalue of $A$. Prove that the determinant $|A-\\lambda I|= 0$.\n",
    "\n",
    "### 1.3 Eigenvalue [7pts]\n",
    "Following 1.2, given a matrix $A$:\n",
    "   $$A = \n",
    "   \\begin{bmatrix} \n",
    "    r & -1 \\\\ \n",
    "    -4 & r \n",
    "    \\end{bmatrix}$$ \n",
    "    \n",
    "Calculate all the eigenvalues of $A$. (Calculation process required. Your answer should be expressed as a function of $r$.)\n",
    "\n",
    "### 1.4 Eigenvector [7pts]\n",
    "Following 1.3, given that the $l_2$ norm of each eigenvector is 1, what are the eigenvectors of matrix $A$? For example, if an eigenvector is \n",
    "    ${v}=\\begin{bmatrix} \n",
    "    x1 \\\\ \n",
    "    x2 \n",
    "    \\end{bmatrix}$, then $||v||_2 = \\sqrt{x_1^2 + x_2^2} = 1$ (Calculation process required.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1 Answer\n",
    "\n",
    "### 1.1 Determinant and Inverse of Matrix [11pts]\n",
    "\n",
    "#### - Calculate the determinant of M.\n",
    "\\begin{equation}\n",
    "det(M) = 4 * (3k-2*6) - 2*(5k-3*6) + 0\n",
    "       = 4(3k-12)-2(5k-18)\n",
    "       = 2k - 12\n",
    "\\end{equation}\n",
    "\n",
    "#### - For which values of k does $M^{-1}$ not exist? Why? [2pts]\n",
    "\n",
    "$M^{-1}$ does not exist iff $M$ is non-singular whereas $det(M)=0$, so $2k-12=0$, we have $k=6$.\n",
    "\n",
    "#### - Calculate $M^{-1}$ for $k=7$. [5pts]\n",
    "\n",
    "Using Gauss-Jordan elimination to find matrix inversion\n",
    "\n",
    "$$[M|I] = \\begin{bmatrix} \n",
    "  4 & 2 & 0 & 1 &0 &0\\\\ \n",
    "  5 & 3 & 6 & 0 &1 &0\\\\\n",
    "  3 & 2 & k & 0 &0 &1\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "  \\rightarrow \\begin{bmatrix} \n",
    "  1 & 1/2 & 0 & 1/4 &0 &0\\\\ \n",
    "  0 & 1/2 & 6 & -5/4 &1 &0\\\\\n",
    "  0 & 1/2 & 7 & -3/4 &0 &1\n",
    "  \\end{bmatrix}\n",
    "$$  \n",
    "\n",
    "$$\n",
    "  \\rightarrow \\begin{bmatrix} \n",
    "  1 & 1/2 & 0 & 1/4 &0 &0\\\\ \n",
    "  0 & 1 & 12 & -5/2 &2 &0\\\\\n",
    "  0 & 0 & 1 & 1/2 & -1 &1\n",
    "  \\end{bmatrix}\n",
    "$$  \n",
    "\n",
    "$$\n",
    "  \\rightarrow \\begin{bmatrix} \n",
    "  1 & 0 & 0 & 9/2 & -7 & 6\\\\ \n",
    "  0 & 1 & 0 & -17/2 & 14 & -12\\\\\n",
    "  0 & 0 & 1 & 1/2 & -1 &1\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "So $M^{-1}$ is the last 3 colums in the matrix above \n",
    "$$M^{-1}= \\begin{bmatrix} \n",
    "  9/2 & -7 & 6\\\\ \n",
    "  -17/2 & 14 & -12\\\\\n",
    "  1/2 & -1 &1\\\\\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "### 1.2 Characteristic Equation [8pts] (BONUS)\n",
    "\n",
    "Since $x$ is a non-zero eigenvector and $\\lambda$ is eigenvalue of $A$,  \n",
    "$Ax=\\lambda x$ has a nontrivial solution  \n",
    "$\\leftrightarrow (A-\\lambda I)x = 0$ has a nontrivial solution  \n",
    "$\\leftrightarrow$ taking $A-\\lambda I$ as an matrix, then $A-\\lambda I$ is not invertible  \n",
    "$\\leftrightarrow$ $A-\\lambda I$ is non singular  \n",
    "$\\leftrightarrow det(A-\\lambda I)=0$  \n",
    "\n",
    "\n",
    "\n",
    "### 1.3 Eigenvalue [7pts]\n",
    "\n",
    "\n",
    "$$det(A-\\lambda I) =0$$\n",
    "\n",
    "\n",
    "$$\n",
    "    det\\begin{bmatrix} \n",
    "    r-\\lambda & -1 \\\\ \n",
    "    -4 & r -\\lambda \n",
    "    \\end{bmatrix}=0\n",
    "$$\n",
    "\n",
    "$$ (r-\\lambda)^{2} - 4 = 0$$  \n",
    "$$ \\lambda = r \\pm 2$$\n",
    "\n",
    "### 1.4 Eigenvector [7pts]\n",
    "\n",
    "when $\\lambda = r + 2$\n",
    "$$\n",
    "    (A-\\lambda I)v = \\begin{bmatrix} \n",
    "    -2 & -1 \\\\ \n",
    "    -4 & -2\n",
    "    \\end{bmatrix}\\begin{bmatrix} \n",
    "    x1 \\\\ \n",
    "    x2 \n",
    "    \\end{bmatrix}=0\n",
    "$$\n",
    "we obtain,\n",
    "$$2x_1 + x_2 = 0$$\n",
    "plug into $||v||_2 = \\sqrt{x_1^2 + x_2^2} = 1$, the corresponding eigenvector is \n",
    "$$\\begin{bmatrix} \n",
    "    x1 \\\\ \n",
    "    x2 \n",
    "    \\end{bmatrix}=\\begin{bmatrix} \n",
    "    \\frac{\\sqrt{5}}{5}\\\\ \n",
    "    \\frac{-2\\sqrt{5}}{5}\n",
    "    \\end{bmatrix}\n",
    "$$   \n",
    "\n",
    "when $\\lambda = r - 2$\n",
    "$$\n",
    "    (A-\\lambda I)v = \\begin{bmatrix} \n",
    "    2 & -1 \\\\ \n",
    "    -4 & 2\n",
    "    \\end{bmatrix}\\begin{bmatrix} \n",
    "    x1 \\\\ \n",
    "    x2 \n",
    "    \\end{bmatrix}=0\n",
    "$$\n",
    "we obtain,\n",
    "$$2x_1 - x_2 = 0$$\n",
    "plug into $||v||_2 = \\sqrt{x_1^2 + x_2^2} = 1$, the corresponding eigenvector is \n",
    "$$\\begin{bmatrix} \n",
    "    x1 \\\\ \n",
    "    x2 \n",
    "    \\end{bmatrix}=\\begin{bmatrix} \n",
    "    \\frac{\\sqrt{5}}{5}\\\\ \n",
    "    \\frac{2\\sqrt{5}}{5}\n",
    "    \\end{bmatrix}\n",
    "$$   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7D5eQGGiZmzV"
   },
   "source": [
    "## 2 Expectation, Co-variance and Independence [25pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cMqPtRogZmzV"
   },
   "source": [
    "Suppose $X, Y$ and $Z$ are three different random variables.\n",
    "Let $X$ obeys Bernouli Distribution. The probability disbribution function is\n",
    "    $$p(x)=\\left\\{\n",
    "    \\begin{array}{c l}\t\n",
    "         0.5 & x = c\\\\\n",
    "         0.5 & x = -c.\n",
    "    \\end{array}\\right.$$\n",
    "    $c$ is a constant here.\n",
    "Let $Y$ obeys the standard Normal (Gaussian) distribution, which can be written as $Y \\sim N(0,1)$. $X$ and $Y$ are independent. Meanwhile, let $Z = XY$.\n",
    "\n",
    "- What is the Expectation and Variance of $X$?(in terms of $c$) [4pts]\n",
    "    \n",
    "- Show that $Z$ also follows a Normal (Gaussian) distribution. Calculate the Expectation and Variance of $Z$. [9pts]\n",
    "        \n",
    "- How should we choose $c$ such that $Y$ and $Z$ are uncorrelated(which means $Cov(Y,Z) = 0$)? [5pts]\n",
    "\n",
    "- Determine whether the following probability is greater than or equal to 0: (1) $P(Y=0)$; (2) $P(Z=c)$; (3) $P(Y\\in(-1,0))$; (4) $P(Z\\in(2c,3c))$; (5) $P(Y\\in(-1,0),Z\\in(2c, 3c))$; (6) $P(Y\\in(-2,-1),Z\\in(c, 2c))$.[3pts]\n",
    "\n",
    "- Are $Y$ and $Z$ independent? Make use of the above probabilities to show your conclusion.[4pts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2 Answer\n",
    "### What is the Expectation and Variance of  ð‘‹ ?(in terms of  ð‘ ) [4pts]\n",
    "\n",
    "$$E(x) = 0.5c + 0.5(-c) = 0$$  \n",
    "\n",
    "$$E(x^{2}) = 0.5c^{2} + 0.5(-c)^{2} = c^{2}$$\n",
    "$$var(x) = E(x^{2}) - E(x)^{2} = c^{2}$$\n",
    "\n",
    "### Show that  ð‘  also follows a Normal (Gaussian) distribution. Calculate the Expectation and Variance of  ð‘ . [9pts]\n",
    "Since $Y ~ N (0,1)$, $$P(Y) =\\frac{1}{\\sqrt{2\\pi}}\\exp\\bigg(-\\frac{(y)^2}{2}\\bigg)$$\n",
    "To prove $Z$ follows normal distribution, \n",
    "$$P(Z) = P(XY)=P(X=c)P(XY|X=c) + P(X=-c)P(XY|X=-c)$$\n",
    "$$= 0.5P(Y|X=c) + 0.5P(Y|X=-c)$$\n",
    "$$= 0.5\\bigg(\\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{(cy)^2}{2})\\bigg) + 0.5\\bigg(\\frac{1}{\\sqrt{2\\pi}}\\exp(-\\frac{(-cy)^2}{2})\\bigg)$$\n",
    "$$ = \\frac{1}{\\sqrt{2\\pi}}\\exp\\bigg(-\\frac{(cy)^2}{2}\\bigg)$$\n",
    "$$ = N(cY)$$\n",
    "Thus, $Z$ is also normally distributed, and $Z \\tilde N (0,c)$,\n",
    "$$E(Z)=0$$\n",
    "$$var(Z) = c^2$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### How should we choose  ð‘  such that  ð‘Œ  and  ð‘  are uncorrelated(which means  ð¶ð‘œð‘£(ð‘Œ,ð‘)=0 )? [5pts]\n",
    "$$cov(Y,Z)= E(YZ)-E(Y)E(Z)$$\n",
    "Since $Z=XY$, \n",
    "$$ cov(Y,Z)= E(XY^{2})-E(Y)E(YX)$$\n",
    "Since both X and Y are independent, then $E(XY)=E(X)E(Y)$, we have  \n",
    "$$ cov(Y,Z)= E(X)E(Y^{2})-E(Y)^{2}E(X)$$\n",
    "$$  = E(X)(E(Y^{2})-E(Y)^{2})$$\n",
    "$$  = E(X)var(Y) $$\n",
    "As Y is normally distributed, $var(Y) = 1$, so\n",
    "$$cov(Y,Z) = E(X) = 0.5c + 0.5(-c)= 0$$ no matter what value $c$ is.\n",
    "\n",
    "\n",
    "### Determine whether the following probability is greater than or equal to 0: (1)  ð‘ƒ(ð‘Œ=0) ; (2)  ð‘ƒ(ð‘=ð‘) ; (3)  ð‘ƒ(ð‘Œâˆˆ(âˆ’1,0)) ; (4)  ð‘ƒ(ð‘âˆˆ(2ð‘,3ð‘)) ; (5)  ð‘ƒ(ð‘Œâˆˆ(âˆ’1,0),ð‘âˆˆ(2ð‘,3ð‘)) ; (6)  ð‘ƒ(ð‘Œâˆˆ(âˆ’2,âˆ’1),ð‘âˆˆ(ð‘,2ð‘)) .[3pts]\n",
    "#### (1) \n",
    "Since $Y$ follows normal distribution which is also continuous, the probability that a normal random variable $Y$ equals any particular value is 0. So $P(Y=0)=0$.\n",
    "\n",
    "#### (2)\n",
    "Since $Z$ follows normal distribution which is also continuous, the probability that a normal random variable $Z$ equals any particular value is 0. So $P(Z=c)=0$.\n",
    "\n",
    "#### (3)\n",
    "$$\\int_{-1}^{0}\\frac{1}{\\sqrt{2\\pi}}\\exp\\bigg(-\\frac{(y)^2}{2}\\bigg)dy = 0.3413>0$$\n",
    "\n",
    "#### (4)\n",
    "$$\\int_{2c}^{3c}\\frac{1}{\\sqrt{2\\pi}}\\exp\\bigg(-\\frac{(cz)^2}{2}\\bigg)dz>0$$ since $(2c,3c)$ is in the third percentile.\n",
    "\n",
    "#### (5)\n",
    "When $c>0$ and $x=c$\n",
    "$$P(Y\\in(âˆ’1,0),Z\\in(2c,3c))=0$$\n",
    "when $x==-c$\n",
    "$$P(Y\\in(âˆ’1,0),Z\\in(2c,3c))>0$$\n",
    "\n",
    "#### (6) \n",
    "When $c>0$ and $x=c$\n",
    "$$P(Y\\in(âˆ’1,0),Z\\in(2c,3c))=0$$\n",
    "when $x==-c$\n",
    "$$P(Y\\in(âˆ’1,0),Z\\in(2c,3c))>0$$\n",
    "\n",
    "\n",
    "### Are  ð‘Œ  and  ð‘  independent? Make use of the above probabilities to show your conclusion.[4pts]\n",
    "Y and Z are not independent. From 2.4 we observe that $P(Y,Z)$ have value greater than 0 depending on $c$, In another word, if $Y$ and $Z$ are independent then $P(Y,Z)=0$ no matter what $c$ is.\n",
    "\n",
    "Another explanation is that, assuming Y and Z are independent, we have \n",
    "$$P(Y|Z) = P(Y)$$\n",
    "$$P(Y|XY) = P(Y)$$\n",
    "$$P(Y|cY) = P(Y)\\quad or \\quad P(Y|-cY) = P(Y)$$ \n",
    "is not correct since the $P(Y|\\pm cY)$ is will be 0 depending on $c$, which does not equal to $P(Y)$. Thus, Y and Z are not independent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hHsbeDGNZmzX"
   },
   "source": [
    "## 3 Maximum Likelihood [25pts + 10pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QSEe9QB9ZmzY"
   },
   "source": [
    "### 3.1 Discrete example[15pts]\n",
    "\n",
    "A box contains poker chips in blue and red. You conduct an experiment to randomly choose three chips from the box with replacement for serveral times. Given that a red chip is equivalent to 2 dollars and a blue chip is 1 dollar, the experiment results are documented in the following table:\n",
    "\n",
    "| No. | Result    |\n",
    "|------|------|\n",
    "|   1  | 5 dollars |\n",
    "|   2  | 4 dollars |\n",
    "|   3  | 3 dollars |\n",
    "|   4  | 6 dollars |\n",
    "|   5  | 4 dollars |\n",
    "|   6  | 3 dollars |\n",
    "\n",
    "- What type of probability distribution does this experiment correspond to [3pts]?\n",
    "\n",
    "- What is the likelihood of the given experiment results assuming the probability of getting a red chip is $\\theta$ [6pts]?\n",
    "\n",
    "- What is maximum likelihood estimation for $\\theta$ [6pts]?\n",
    "    \n",
    "    \n",
    "### 3.2 Poisson distribution [5pts]\n",
    "\n",
    "The Poisson distribution is defined as \n",
    "\n",
    "$$P(X=k)=\\frac{\\lambda^k e^{-\\lambda}}{k!} (k=0,1,2,...).$$\n",
    "\n",
    "What is the maximum likelihood estimator of $\\lambda$?(Suppose we have $n$ i.i.d data points $x_1,\\dots,x_n$).\n",
    "\n",
    "### 3.3 Gaussian distribution [5pts]\n",
    "\n",
    "The probability density function of Gaussian distribution is given by\n",
    "\n",
    "$$p(x;\\mu,\\sigma^2)=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\bigg(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\bigg)$$\n",
    "\n",
    "What is the maximum likelihood estimator of $\\mu$ and $\\sigma^2$?(Suppose we have $n$ i.i.d data points $x_1,\\dots,x_n$).\n",
    "\n",
    "### 3.4 Bonus [10pts]\n",
    "\n",
    "Given $n$ i.i.d. observations $\\{(x_i,y_i)\\}_{i=1}^n\\in \\mathbb{R}^d\\times\\{-1,1\\}$, we assume\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(y_i=1|x_i)=h(x_i^T\\theta) \\ \\ \\  \\text{and} \\ \\ \\  \\mathbb{P}(y_i=-1|x_i)=1-h(x_i^T\\theta),\n",
    "$$\n",
    "where $h(x)=\\frac{1}{1+\\exp(-x)}$ and $\\theta$ is the model parameter and $\\theta=(\\theta_1, \\theta_2, \\dots, \\theta_d)^\\top$.\n",
    "\n",
    "Write out the likelihood function $L(\\theta)$ given $(x_i,y_i)$. Then formulate the log-likelihood function.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part3 Answer\n",
    "### 3.1 Discrete example[15pts]Â¶\n",
    "#### What type of probability distribution does this experiment correspond to [3pts]?\n",
    "Joint Probability Distribution (discrete).\n",
    "#### What is the likelihood of the given experiment results assuming the probability of getting a red chip is  ðœƒ  [6pts]?\n",
    "The above table could be interpreted as in number of red chips:\n",
    "\n",
    "| No. | Result    | Red Chips |\n",
    "|------|------|-----|\n",
    "|   1  | 5 dollars | 2 |\n",
    "|   2  | 4 dollars | 1 | \n",
    "|   3  | 3 dollars | 0 |\n",
    "|   4  | 6 dollars | 3 |\n",
    "|   5  | 4 dollars | 1 |\n",
    "|   6  | 3 dollars | 0 |\n",
    "\n",
    "Then each trial consists of three independent experiments with probability of getting a red chip is $\\theta$ and getting a blue chip is $1-\\theta$ for each experiment.\n",
    "$$p(\\theta) = P(No1)*P(No2)*P(No3)*P(No4)*P(No5)*P(No6)$$\n",
    "$$ = {3 \\choose 2}[\\theta*\\theta*(1-\\theta)] * {3 \\choose 1}[\\theta*(1-\\theta)*(1-\\theta)] * {3 \\choose 0}[(1-\\theta)*(1-\\theta)*(1-\\theta)] * {3 \\choose 3}[\\theta*\\theta*\\theta] * {3 \\choose 1}[\\theta*(1-\\theta)*(1-\\theta)] * {3 \\choose 0}[(1-\\theta)*(1-\\theta)*(1-\\theta)]$$\n",
    "\n",
    "$$=27\\theta^{7}(1-\\theta)^{11}$$\n",
    "\n",
    "#### What is maximum likelihood estimation for  ðœƒ  [6pts]?\n",
    "$$p(\\theta)'=27(7\\theta^6(1-\\theta)^{11}-11\\theta^7(1-\\theta)^{10})=0$$\n",
    "$$-\\theta^6(\\theta-1)^{10}(18\\theta-7)=0$$\n",
    "$$\\theta = 0, 1, \\frac{7}{18}$$\n",
    "The maximum equals to $\\frac{24*11^{11}\\cdot823543}{*18^{18}}$ at $\\theta = \\frac{7}{18}$.\n",
    "\n",
    "\n",
    "### 3.2 Poisson distribution [5pts]\n",
    "$$P(X=k)=\\frac{\\lambda^k e^{-\\lambda}}{k!} (k=0,1,2,...).$$\n",
    "The joint distribution is $$l(X = x_i) = \\prod_{i=1}^{n} \\frac{\\lambda^{x_i} e^{-\\lambda}}{x_i!}$$\n",
    "Taking the log to find maximum likelihood estimation for $\\lambda$\n",
    "$$L(\\lambda) = log\\prod_{i=1}^{n} \\frac{\\lambda^{x_i} e^{-\\lambda}}{x_i!}$$\n",
    "$$ = \\sum_{i=1}^{n} (x_ilog\\lambda-\\lambda-logx_i!)$$\n",
    "Finding the maximum by calculating derivative\n",
    "$$ log\\lambda \\sum_{i=1}^{n} x_i-n = 0$$\n",
    "$$ \\lambda = \\frac{1}{n} \\sum_{i=1}^{n} x_i$$\n",
    "\n",
    "\n",
    "### 3.3 Gaussian distribution [5pts]\n",
    "$$l(x;\\mu,\\sigma^2)=\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\bigg(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\bigg)$$\n",
    "The joint distribution is $$P(X = x_i;\\mu,\\sigma^2) = \\prod_{i=1}^{n} \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\bigg(-\\frac{(x_i-\\mu)^2}{2\\sigma^2}\\bigg)$$\n",
    "$$= ({2\\pi}\\sigma^2)^{-n/2}\\exp\\bigg(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(x_i-\\mu)^2\\bigg)$$\n",
    "\n",
    "Taking the log to find maximum likelihood estimation for $\\mu$ and $\\sigma^2$\n",
    "$$L(x;\\mu,\\sigma^2) = log\\Bigg(({2\\pi}\\sigma^2)^{-n/2}\\exp\\bigg(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(x_i-\\mu)^2\\bigg)\\Bigg) $$\n",
    "$$ = log(({2\\pi}\\sigma^2)^{-n/2}) + log\\Bigg(\\exp\\bigg(-\\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(x_i-\\mu)^2\\bigg)\\Bigg)$$\n",
    "$$ = -\\frac{n}{2}log({2\\pi}\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(x_i-\\mu)^2$$\n",
    "\n",
    "To find maximum likelihood of $\\mu$, taking the partial derivative of $\\mu$\n",
    "$$\\frac{\\partial}{\\partial u}L(x;\\mu,\\sigma^2)=\\frac{\\partial}{\\partial u}\\bigg(-\\frac{n}{2}log({2\\pi}\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(x_i-\\mu)^2\\bigg)$$\n",
    "$$ = \\frac{1}{\\sigma^2}\\sum_{i=1}^{n}(x_i-n\\mu) = 0$$\n",
    "$$\\sum_{i=1}^{n}(x_i-n\\mu) = 0$$\n",
    "$$\\mu = \\frac{1}{n} \\sum_{i=1}^{n} x_i$$\n",
    "\n",
    "\n",
    "To find maximum likelihood of $\\sigma^2$, taking the partial derivative of $\\sigma^2$\n",
    "$$\\frac{\\partial}{\\partial \\sigma^2}L(x;\\mu,\\sigma^2)=\\frac{\\partial}{\\partial \\sigma^2}\\bigg(-\\frac{n}{2}log({2\\pi}\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{n}(x_i-\\mu)^2\\bigg)$$\n",
    "$$=-\\frac{n}{2\\sigma^2}+\\sum_{i=1}^{n}(x_i-\\mu)^2\\frac{1}{(2\\sigma^2)^2}$$\n",
    "$$=\\frac{n}{2\\sigma^2}\\bigg(\\frac{1}{\\sigma^2}\\sum_{i=1}^{n}(x_i-\\mu)^2-n\\bigg)=0$$\n",
    "We obtain\n",
    "$$\\sigma^2 = \\frac{1}{n}\\sum_{i=1}^{n}(x_i-\\mu)^2$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 3.4 Bonus [10pts]\n",
    "Given\n",
    "$$\n",
    "\\mathbb{P}(y_i=1|x_i)=h(x_i^T\\theta) \\ \\ \\  \\text{and} \\ \\ \\  \\mathbb{P}(y_i=-1|x_i)=1-h(x_i^T\\theta),\n",
    "$$\n",
    "Y follows a Bernoulli distribution with value of either -1 or 1,\n",
    "$$l(\\theta) = f(x_i,y_i|\\theta) = \\prod_{i=1}^{n}h(x_i^T\\theta)^{(y+1)/2}*(1-h(x_i^T\\theta))^{(-y+1)/2}$$\n",
    "where  $h(x_i^T\\theta)=\\frac{1}{1+\\exp(-x_i^T\\theta)}$.\n",
    "\n",
    "$$L(\\theta) = \\sum_{i=1}^{n}logh(x_i^T\\theta)^{(y+1)/2}*(1-h(x_i^T\\theta))^{(-y+1)/2}$$\n",
    "$$ = \\sum_{i=1}^{n}\\bigg(\\frac{y+1}{2}\\bigg)logh(x_i^T\\theta) + \\sum_{i=1}^{n}(\\frac{-y+1}{2})log(1-h(x_i^T\\theta))$$\n",
    "$$ = \\sum_{i=1}^{n}\\bigg(\\frac{y+1}{2}\\bigg)log\\frac{1}{1+\\exp(-x_i^T\\theta)} + \\sum_{i=1}^{n}\\bigg(\\frac{-y+1}{2}\\bigg)log\\bigg(1-\\frac{1}{1+\\exp(-x_i^T\\theta)}\\bigg)$$\n",
    "$$ = -\\sum_{i=1}^{n}\\bigg(\\frac{y+1}{2}\\bigg)log\\bigg(1+\\exp(-x_i^T\\theta)\\bigg) + \\sum_{i=1}^{n}\\bigg(\\frac{-y+1}{2}\\bigg)log\\bigg(\\frac{\\exp(-x_i^T\\theta)}{1+\\exp(-x_i^T\\theta)}\\bigg)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ym8gpKMHZmzY"
   },
   "source": [
    "## 4 Information Theory [25pts + 7pts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3HSWti__DYx9"
   },
   "source": [
    "### 4.1 Marginal Distribution [6pts]\n",
    "Suppose the joint probability distribution of two binary random variables $X$ and $Y$ are given as follows.\n",
    "$$\n",
    "\\begin{array}{|c|c|c|}\\hline X \\backslash Y & {1} & {2} \\\\ \\hline 0 & {\\frac{1}{3}} & {\\frac{1}{3}} \\\\ \\hline 1 & {0} & \\frac{1}{3} \\\\ \\hline\\end{array}\n",
    "$$\n",
    "\n",
    "- Show the marginal distribution of $X$ and $Y$, respectively. [3pts]\n",
    "- Find mutual information for the joint probability distribution in the previous question [3pts]\n",
    "    \n",
    "### 4.2 Mutual Information and Entropy [19pts]\n",
    "Given a dataset as below.\n",
    "$$\n",
    "\\begin{array}{|c|c|c|c|c|c|}\\hline Sr.No. & Age & Income & Student? & Credit Rating & Buys Computer? \\\\ \\hline 1 & young & high & no & fair & no \\\\ \\hline 2 & young & high & no & excellent & no \\\\ \\hline 3 & middle aged & high & no & fair & yes \\\\ \\hline 4 & senior & medium & no & fair & yes \\\\ \\hline 5 & senior & low & yes & fair & yes \\\\ \\hline 6 & senior & low & yes & excellent & no \\\\ \\hline 7 & middle aged & low & yes & excellent & yes\\\\ \\hline 8 & young & medium & no & fair & no\\\\ \\hline 9 & young & low & yes & fair & no\\\\ \\hline 10 & senior & medium & yes & fair & yes\\\\ \\hline 11 & young & medium & yes & excellent & yes \\\\ \\hline 12 & middle aged & medium & no & excellent & yes \\\\ \\hline 13 & middle aged & high & yes & fair & yes \\\\ \\hline 14 & senior & medium & no & excellent & no \\\\\\hline\\end{array}\n",
    "$$\n",
    "\n",
    "We want to decide whether a customer buys a computer or not. Each input has four features ($x_1$, $x_2$, $x_3$, $x_4$): Age, Income, Student, Credit Rating. The decision (buy vs does not buy) is represented as $Y$.\n",
    "\n",
    "- Find entropy $H(Y)$. [3pts]\n",
    "\n",
    "  \n",
    "  \n",
    "- Find conditional entropy $H(Y|x_1)$, $H(Y|x_4)$, respectively. [8pts]\n",
    "  \n",
    "  \n",
    "  \n",
    "- Find mutual information $I(x_1, Y)$ and $I(x_4, Y)$ and determine whether which one ($x_1$ or $x_4$) is more informative. [4pts]\n",
    "\n",
    "\n",
    "\n",
    "- Find joint entropy $H(Y, x_3)$. [4pts]\n",
    "  \n",
    "  \n",
    "### 4.3 Bonus Question [7pts]\n",
    "- Suppose $X$ and $Y$ are independent. Show that $H(X|Y) = H(X)$. [2pts]\n",
    "\n",
    "\n",
    "- Suppose $X$ and $Y$ are independent. Show that $H(X,Y) = H(X) + H(Y)$. [2pts]\n",
    "\n",
    "\n",
    "  \n",
    "- Prove that the mutual information is symmetric, i.e., $I(X, Y) = I(Y, X)$ and $x_i \\in X, y_i \\in Y$ [3pts]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part4 Answer\n",
    "### 4.1 Marginal Distribution [6pts]\n",
    "#### Show the marginal distribution of  ð‘‹  and  ð‘Œ , respectively. [3pts]\n",
    "$$P_x(x=0)=\\frac{1}{3}+\\frac{1}{3}=\\frac{2}{3}$$\n",
    "$$P_x(x=1)=0+\\frac{1}{3}=\\frac{1}{3}$$\n",
    "\n",
    "$$P_y(y=1)=\\frac{1}{3}+0=\\frac{1}{3}$$\n",
    "$$P_y(y=2)=\\frac{1}{3}+\\frac{1}{3}=\\frac{2}{3}$$\n",
    "\n",
    "#### Find mutual information for the joint probability distribution in the previous question [3pts]\n",
    "\n",
    "$$I(X,Y) = \\sum_{x \\in X, y \\in Y} p(x,y)log(\\frac{p(x,y)}{p(x)p(y)})$$\n",
    "$$ = p(0,1)log(\\frac{p(0,1)}{p(0)p(1)})+p(1,1)log(\\frac{p(1,1)}{p(1)p(1)})+ p(0,2)log(\\frac{p(0,2)}{p(0)p(2)})+ p(1,2)log(\\frac{p(1,2)}{p(1)p(2)})$$\n",
    "$$ = \\frac{1}{3}log(\\frac{\\frac{1}{3}}{\\frac{2}{3}\\cdot \\frac{1}{3}}) + 0+ \\frac{1}{3}log(\\frac{\\frac{1}{3}}{\\frac{2}{3}\\cdot \\frac{2}{3}})+ \\frac{1}{3}log(\\frac{\\frac{1}{3}}{\\frac{1}{3}\\cdot \\frac{2}{3}})$$\n",
    "$$ = 0.917$$\n",
    "\n",
    "\n",
    "### 4.2 Mutual Information and Entropy  [19pts]\n",
    "\n",
    "#### Find entropy  ð»(ð‘Œ) . [3pts]\n",
    "$$P(yes)= \\frac{4}{7}, P(no) = \\frac{3}{7}$$\n",
    "$$H(Y) = \\sum\\limits_1^n P(y_i)log(\\frac{1}{P(y_i)})$$\n",
    "$$= \\frac{3}{7}log_2\\frac{7}{3} + \\frac{4}{7}log_2\\frac{7}{4}$$\n",
    "$$ = 0.98522$$\n",
    "\n",
    "\n",
    "#### Find conditional entropy  ð»(ð‘Œ|ð‘¥1) ,  ð»(ð‘Œ|ð‘¥4) , respectively. [8pts]\n",
    "\n",
    "$$H(Y|x_i) = \\sum\\limits_1^n P(Y,x_i)log(\\frac{1}{P(Y|x_i)})$$\n",
    "For $x_1$\n",
    "$$P(Y=yes|x_1= young) = \\frac{1}{5} \\quad P(Y=yes|x_1= middleage) = 1 \\quad P(Y=yes|x_1= senior) = \\frac{3}{5} $$\n",
    "$$ P(Y=no|x_1= young) = \\frac{4}{5}\\quad P(Y=no|x_1= middleage) = 0 \\quad P(Y=no|x_1= senior) = \\frac{2}{5}$$\n",
    "\n",
    "$$P(Y=yes \\cap x_1= young) = \\frac{1}{14}\\quad P(Y=yes \\cap x_1= middleage) = \\frac{4}{14}\\quad P(Y=yes \\cap x_1= senior) = \\frac{3}{14}$$\n",
    "$$P(Y=no \\cap x_1= young) = \\frac{4}{14}\\quad P(Y=no \\cap x_1= middleage) = 0\\quad P(Y=no \\cap x_1= senior) = \\frac{2}{14}$$ \n",
    "\n",
    "$$H(Y|x_1)=\\frac{1}{14}log(5)+\\frac{4}{14}log(1)+\\frac{3}{14}log(\\frac{5}{3})+\\frac{4}{14}log(\\frac{5}{4})+\\frac{2}{14}log(\\frac{5}{2})$$\n",
    "$$ = 0.6046$$\n",
    "\n",
    "For $x_4$\n",
    "$$P(Y=yes|x_4= fair) = \\frac{6}{8}\\quad P(Y=yes|x_4= excellent) = \\frac{1}{2}$$\n",
    "$$P(Y=no|x_4= fair) = \\frac{2}{8}\\quad P(Y=no|x_4= excellent) = \\frac{1}{2}$$\n",
    "\n",
    "$$P(Y=yes \\cap x_4= fair) = \\frac{6}{14}\\quad P(Y=yes \\cap x_4= excellent) = \\frac{3}{14}$$\n",
    "$$P(Y=no \\cap x_4= fair) = \\frac{2}{14}\\quad P(Y=no \\cap x_4= excellent) = \\frac{3}{14}$$ \n",
    "\n",
    "$$H(Y|x_4)=\\frac{6}{14}log(\\frac{8}{6})+\\frac{3}{14}log(2)+\\frac{2}{14}log(4)+\\frac{3}{14}log(2)$$\n",
    "$$ = 0.8922$$\n",
    "\n",
    "\n",
    "#### Find mutual information  ð¼(ð‘¥1,ð‘Œ)  and  ð¼(ð‘¥4,ð‘Œ)  and determine whether which one ( ð‘¥1  or  ð‘¥4 ) is more informative. [4pts]\n",
    "$$H(Y)=1$$\n",
    "$$I(x_1,Y) = H(Y) - H(Y|X_1)$$\n",
    "$$ = 0.98522-0.6046 = 0.381$$\n",
    "$$I(x_4,Y) = H(Y) - H(Y|X_4)$$\n",
    "$$ = 0.98522-0.8922 = 0.093$$\n",
    "\n",
    "\n",
    "#### Find joint entropy  ð»(ð‘Œ,ð‘¥3) . [4pts]\n",
    "$$P(Y=yes \\cap x_3= yes) = \\frac{5}{14}\\quad P(Y=yes \\cap x_3= no) = \\frac{3}{14}$$\n",
    "$$P(Y=no \\cap x_3= yes) = \\frac{2}{14}\\quad P(Y=no \\cap x_3= no) = \\frac{4}{14}$$ \n",
    "\n",
    "$$H(Y,x_3) = \\sum P(Y,X_3)log(\\frac{1}{P(Y,x_3)})$$\n",
    "$$= \\frac{5}{14}log(\\frac{14}{5}) + \\frac{3}{14}log(\\frac{14}{5}) +\\frac{2}{14}log(\\frac{14}{2}) + \\frac{4}{14}log(\\frac{14}{4})$$\n",
    "$$= 1.9241$$\n",
    "\n",
    "### 4.3 Bonus Question [7pts]\n",
    "#### Suppose  ð‘‹  and  ð‘Œ  are independent. Show that  ð»(ð‘‹|ð‘Œ)=ð»(ð‘‹) . [2pts]\n",
    "Since $X$ and $Y$ are independent, so $I(Y,X)=0$,\n",
    "$$I(Y,X) = H(X) - H(X|Y)$$\n",
    "$$0 = H(X) - H(X|Y)$$\n",
    "which is \n",
    "$$H(X) = H(X|Y)$$\n",
    "\n",
    "#### Suppose  ð‘‹  and  ð‘Œ  are independent. Show that  ð»(ð‘‹,ð‘Œ)=ð»(ð‘‹)+ð»(ð‘Œ) . [2pts]\n",
    "$$H(X,Y) = H(Y) + H(X|Y)$$\n",
    "From previous question, $ H(X|Y)=H(X)$\n",
    "So, $$H(X,Y) = H(Y) + H(X)$$\n",
    "\n",
    "#### Prove that the mutual information is symmetric, i.e.,  ð¼(ð‘‹,ð‘Œ)=ð¼(ð‘Œ,ð‘‹)  and  ð‘¥ð‘–âˆˆð‘‹,ð‘¦ð‘–âˆˆð‘Œ  [3pts]\n",
    "The mutual infomation can be represented as\n",
    "$$I(X,Y) = \\sum P(X,Y)log(\\frac{P(X,Y)}{P(X)*P(Y)})$$\n",
    "$$I(Y,X) = \\sum P(Y,X)log(\\frac{P(Y,X)}{P(Y)*P(X)})$$\n",
    "where\n",
    "$P(X,Y)= P(Y,X)$\n",
    "So $$I(X,Y) \\sum P(Y,X)log(\\frac{P(Y,X)}{P(Y)*P(X)})=I(Y,X)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Probability [5pts] (BONUS FOR ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to recent customer unsatisfaction, Amazon is reevaluating their prime 2-day shipping policy to determine whether their shipping guarantee should be 1-day, 3-day, or remain 2-day. In order to do this, Amazon is using a new package verification system to analyze the punctuality of its shipped packages from different distances. The new system classifies travel distance as less than 1000 miles, less than 2000 miles, and less than 3000 miles and classifies arrival time as 1 day, 2 days, 3 days. From their records, 10% of packages arrive in 1 day and 65% of packages arrive in 2 days. Packages travel less than 2000 miles 85% of the time and less than 1000 miles 50% of the time. Also, the probability that a package arrives in a day if it travelled greater than 2000 miles is 0. The probability of a package arriving in 1 day and travelling less than 1000 miles is equal to the probability of a package travelling from 1000 miles up to 2000 miles and arriving in 1 day. Assume no packages take more than 3 days to arrive or travel more than 3000 miles.\n",
    "\n",
    "- Determine the probability that a package travels greater than 2000 miles but less than 3000 miles. [1pts]\n",
    "\n",
    "Further analysis shows that 10% of the packages that travel greater than 1000 miles but less than 2000 miles arrive in 3 days.\n",
    "\n",
    "- Determine the probability that a package will arrive in 1 day if it traveled greater than 1000 miles but less than 2000 miles. [2pts]\n",
    "\n",
    "- Determine the probability that a package will arrive in 1 day if it traveled less than 1000 miles. [1pts]\n",
    "\n",
    "- Determine the probability that if a package arrived in 3 days, it traveled greater than 1000 miles but less than 2000 miles.. [1pts]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part5 Answer\n",
    "\n",
    "### Determine the probability that a package travels greater than 2000 miles but less than 3000 miles. [1pts]\n",
    "$$P(day=3) = 1-85\\%=15\\%$$\n",
    "\n",
    "### Determine the probability that a package will arrive in 1 day if it traveled greater than 1000 miles but less than 2000 miles. [2pts]\n",
    "\n",
    "\n",
    "Since $$P(day=1|mile>2000)=0=P(day=1 \\cap mile>2000)/P(mile>2000)$$\n",
    "we have $$P(day=1 \\cap mile>2000)=0$$\n",
    "we know $$P(1000<mile<2000 \\cap day=1)=P(day=1 \\cap mile<1000)=\\frac{10\\%-0}{2}=5\\%$$\n",
    "$$P(day=1|1000<miles<2000) = P(1000<mile<2000 \\cap day=1)/P(1000<miles<2000) = \\frac{5\\%}{35\\%}=14.2\\%$$\n",
    "\n",
    "### Determine the probability that a package will arrive in 1 day if it traveled less than 1000 miles. [1pts]\n",
    "$$P(day=1|miles<1000)= P(day=1\\cap miles<1000)/P(miles<1000)= \\frac{5\\%}{50\\%}=10\\%$$\n",
    "\n",
    "### Determine the probability that if a package arrived in 3 days, it traveled greater than 1000 miles but less than 2000 miles.. [1pts]\n",
    "$$P(day=3)=1-10\\%-65\\%=25\\%$$\n",
    "$$P(1000<miles<2000|day=3) = P(day=3\\cap 1000<miles<2000)/P(day=3)=\\frac{10\\%}{25\\%}=40\\%$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw1-template.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
